import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score

# --- 1. Load Data ---
# Note: Assuming 'salaries.csv' is in the same directory.
try:
    df = pd.read_csv('salaries.csv')
except FileNotFoundError:
    print("Error: 'salaries.csv' not found. Please ensure the data file is present.")
    exit()

# --- 2. Preprocessing Steps (Following your notebook) ---

# Drop duplicates (Critical for accurate model evaluation)
df.drop_duplicates(inplace=True)

# 2.1. Feature Selection and Encoding Setup
categorical_cols = ["experience_level", "employment_type", "job_title", 
                    "salary_currency", "employee_residence", "company_location", 
                    "company_size"]
le = LabelEncoder()

# Fit and Transform Categorical Columns
for col in categorical_cols:
    # IMPORTANT: The LabelEncoder instance (le) is re-fitted in every loop, 
    # meaning only the last column's mapping is saved. 
    # For deployment, you usually need a separate fitted encoder for *each* column, 
    # or use a Pipeline with ColumnTransformer, but we will save the LE instance 
    # to maintain the original structure of your notebook.
    le.fit(df[col])
    df[col] = le.transform(df[col])

# --- 3. Correct Scaling, Splitting, and Training ---

# 3.1. Separate X and y
# 'salary' and 'salary_currency' columns are redundant since 'salary_in_usd' (index 6) is the target.
# We will drop 'salary' (index 4) and 'salary_currency' (index 5)
# and keep 'salary_in_usd' as the target (y).
X_cols_to_drop = [4, 5, 6] 
X = df.drop(columns=['salary', 'salary_currency', 'salary_in_usd']).values
y = df['salary_in_usd'].values

# NOTE: The notebook had a data leakage issue by scaling the entire DataFrame first.
# This corrected approach splits first, then scales.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# 3.2. Fit StandardScaler (ss) on training data only
ss = StandardScaler()
X_train_scaled = ss.fit_transform(X_train)
X_test_scaled = ss.transform(X_test) # Correct scaling for test data

# --- 4. Train the Final Model ---
# The notebook identified RandomForestRegressor (rf) as the best model (R2=0.99)
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train_scaled, y_train)

# --- 5. Save the Model Bundle (.pkl) ---

# Create a dictionary containing all necessary objects for deployment
model_bundle = {
    'model': rf,
    'scaler': ss,
    'label_encoder': le, # Note: This will only contain the last fitted LE mapping (company_size)
    'feature_names': list(df.drop(columns=['salary', 'salary_currency', 'salary_in_usd']).columns)
}

filename = "model_bundle.pkl"

with open(filename, "wb") as file:
    pickle.dump(model_bundle, file)

print(f"\nSuccessfully trained the RandomForest model and saved the model, scaler, and encoder to '{filename}'")
print(f"R2 score on test set (with corrected scaling): {r2_score(y_test, rf.predict(X_test_scaled)):.4f}")